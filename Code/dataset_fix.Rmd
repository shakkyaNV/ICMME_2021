---
title: "ICMME - Merge_initial_Dataset fix"
author: "eNVy"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NULL)
# knitr::opts_chunk$set(warning = F, message = F) # Un-comment at the end
```

```{r libs, include = F}
library(tidyverse)
library(magrittr)
library(rlang)
```

# Dataset import RAW

```{r import, warning=F, message=F}
raw_df <- read_csv("../Data/heavy/merge_initial.csv", 
                   col_names = T,
                   col_types = cols(Code = "c", award = "f", 
                                    .default = col_double()), 
                   )
raw_df %>% head()

```

# Indicator dfs
```{r import, warning=F, message=F}
ind_list <- list.files(path = "../Data/heavy/", 
                                pattern = "*indicator.csv", 
                                full.names = T)
indicator_nested_tbl <- map(ind_list, read_csv)

indicator_temp_names <- ind_list %>% 
  str_remove(pattern = "../Data/heavy/") %>% 
  str_remove(pattern = ".csv")

for (i in 1:length(indicator_temp_names)) {
  assign(indicator_temp_names[i], indicator_nested_tbl[[i]])
}
```

# Remove possible indicators

```{r}
temp <- raw_df %>% sample_n(5) %>% t() %>% data.frame() %>% 
  rownames_to_column(var = "INDICATOR_CODE")

temp %>% left_join(y = API_8_indicator, 
                   by = 'INDICATOR_CODE')  %>% 
  select(c(1,7)) %>% View()

# possible remove indices are in to be removed.txt
```


# Fix dataset

To do within data set
  
  + Fix NA
    + Count NA
      + By country
      + By year
      + By index
      
    + Removed before
      + A --> If all NA for every index for given country_index (All years) (NA Horz) -- Remove country_index
      + B --> If all NA for every country_index for given index             (NA Vert) -- Remove index
      + C --> If all NA for every year for a given country for a given index (NA Vert, 1984 - 2017) -- Remove country
      
    + Fix how?
      + A --> Check the y data set in ```left merge``` for **country_names** conflicts
      + B --> No solution
      + C --> Can replace value by other related category mean (eg. SP.POP.5054.MA.5Y NA replaced by SA.POP category in same years/country_index )
      
    + Replace NA
      + prev by mean() 
      + try linear approx()
      + Time series ar() approx()
      
  + New indices
    + Add vars by down sampling for consistency
    + possible new indices
      + Coffee index


# Find which countries have less information (Type A)

```{r}
raw_df %>% 
  mutate(
    rowSumNA = rowSums(is.na(raw_df))
  ) %>% group_by(Year, Code) %>% select(Year, Code, rowSumNA) %>% 
  arrange(rowSumNA, Code, Year) %>% unique() # %>% View()

# 245 after removing incidec from to_be_removed.txt and prop > 0.8

raw_df %>% filter(Code == "ALG")
```

# Count and proportion of NA by variable (Type B)

```{r}
# test <- raw_df %>% head(40) %>% select(1:10)
temp2 <- raw_df %>% 
  summarise(
  across(everything(), ~sum(is.na(.x)))
            ) %>% t() %>% data.frame()

temp2 %<>%  rownames_to_column()

temp2 %>% 
  mutate(
  prop = ./(dim(raw_df)[1])
        ) %>% arrange(desc(prop)) -> temp3
  # filter(str_detect(rowname, "govt_expn"))
```


# NA count for each index grouped by Year

```{r}
what <- (raw_df %>% 
           group_by(Code) %>% 
           summarise(Count = n())) %>% 
  select(Code, Count)

temp4 <- raw_df %>% # select(c(1,2,4:10)) %>% 
  # filter(Code == "GDR" | Code == "USS") %>% 
  group_by(Code) %>% 
  summarise(
    across(everything(), ~sum(is.na(.x)))
  ) %>% 
  select(-c(Year, award)) %>% arrange(Code) 

temp5 <- bind_cols(what, temp4)
View(temp5)

# temp5

# remove years with matching Counts and NAs
```


```{r}
# make a copy of raw_df before proceeding
raw_df -> raw_dfCopy
```

# Remove selected ```indices``` and ```Codes```

## Remove indices pre identified via manual search of indices

```{r}
# from tobe_removed.txt
to_be_removed <- c(18:21, 23,25, 39, 41, 43,65, 67, 69, 77, 79, 81, 111, 115,116, 118,119, 121:124, 126,127, 129,130, 135, 137, 139, 141, 140, 144,145, 146, 178, 206, 221, 271, 281, 284, 286, 288, 314, 315, 329:331, 335, 342, 340, 367, 398, 426)

raw_df_test <- raw_df %>% select(-all_of(to_be_removed))
```

resulting dim() = 14835 372
rerun above codes to see diff.

## Remove indices with more than `r upper_bound_prop` empty prop

```{r}
upper_bound_prop = 0.6

temp3 %>% filter(prop > upper_bound_prop) %>% 
  pull(var = rowname) %>% 
  as.vector() -> var_indiceRemove_tooManyNA 

raw_df_test %<>% select(-any_of(var_indiceRemove_tooManyNA))
# check and remove necessary
```


```{r}
raw_df_test %>% dim()

raw_df %>% dim()
```

```{r}
raw_df_test -> raw_df_testCopy
raw_df_test %<>% select(-award) %>% unique() 
```


```{r}
# row wise NA's

test_one <- raw_df_test %>% 
  mutate(
    rowSumNA = rowSums(is.na(raw_df_test))
          ) %>% 
  group_by(Year, Code) %>% 
  select(Year, Code, rowSumNA) %>% 
  arrange(rowSumNA) %>% 
  unique()

test_two <- test_one %>% group_by(Year, Code) %>% 
  summarise(
    maxRow = max(rowSumNA)
            ) %>% 
  arrange(Code, Year, desc(maxRow)) %>% 
  filter(maxRow > 100)

df_to_lm <- anti_join(raw_df_test, y = test_two, by = c('Year', 'Code'))
```

*************

# Start from here maybe?

```{r}
# write_csv(df_to_lm, "../Data/heavy/lm_initial.csv")

df_to_lm <- read_csv("../Data/heavy/lm_initial.csv", 
                   col_names = T,
                   col_types = cols(Code = "c", 
                                    .default = col_double()))

df_to_lm %>% dim()

```

# Row wise NAs in df_LM

```{r}
df_to_lm %>% 
  mutate(
    rowSumNA = rowSums(is.na(df_to_lm))
  ) %>% group_by(Year, Code) %>% 
  select(Year, Code, rowSumNA) %>% 
  arrange(desc(rowSumNA), Code, Year) %>% 
  unique()
```

# Col wise NAs in df_LM

```{r}
temp4 <- df_to_lm %>% 
  summarise(
  across(everything(), ~sum(is.na(.x)))
            ) %>% t() %>% data.frame()

temp4 %<>%  rownames_to_column()

temp4 %>% 
  mutate(
  prop = ./(dim(df_to_lm)[1])
        ) %>% 
  arrange(desc(prop))
```

# Main functions test with test_lm

```{r}
test_lm <- df_to_lm %>% 
  filter(Code == "BLR" | Code == "AUS", Year > 2000, Year < 2015) %>% 
  select(1:7)

# when testing with many Codes fix the below indexing
test_lm[1, 3] = 5
test_lm[14, 6] = 80
test_lm[13, 6] = NA # real value is 89
test_lm[10, 5] = NA # real value is 3.06
test_lm[6, 6] = NA # real value is 68.80
test_lm[6, 3] = NA
```



```{r}
# function get position
getPos <- function(df, var, posList, gpvar, m) {

  var <- enquo(var)
  
  rows <- df %>% 
    select(Code, !!var) %>% 
    mutate(T = is.na(!!var) & Code == gpvar) %>% 
    pull(T) %>% which(arr.ind = T) %>% 
    as.vector()
  
  # rows <- which(is.na(varCol), arr.ind = T)  %>% 
  #   as.vector() # which indices in given var
  
  colIndex <- (df %>% names() ) %in% as_label(var) %>% 
    which()
  
  # create a lsit with row positions and column index number
  # return(list(rows = rows, cols = colIndex))
  posList[[sym(gpvar)]] = list(rows = rows, cols = colIndex)
  
  if(is_empty(rows)){
    warning("No NAs to replace, 
            Skipping to next Code \n")
    return(NULL) # skip the considering code
  }
  
  if (length(rows) == m) {
    warning("All obs are NAs. Can't replace. 
            Skipping to next Code \n")
    print(m)
    return(NULL) # skip the considering code
  }
  
  return(posList) # maybe use colon equal := 
}
```


```{r}
# group by tibble for each country within the set index
get_gp_tbl <- function(df, var) {
  
  # var = fixing variable
  # gpvar = Each country code to group_by
  var = enquo(var)
  
  # get NA information of other columns --> predict
  df_var_na <- df %>% 
    filter_at(vars(everything()), any_vars(is.na(.))) %>% 
    select(-!!var) 
  
  # remove all NA for cor() and fit.lm()
  df %<>% na.omit()
  
  # Find var with most correlation
  suppressWarnings( 
    cor_tbl <- df %>% 
    select(-Code) %>% 
    cor() %>% as_tibble()
  )
  
  suppressWarnings(
    rownames(cor_tbl) <- colnames(cor_tbl)
  )
  
  cor_tbl %<>% rownames_to_column(var = "Index")
  
  # set symbols and get variables with high correlation
  Index <- rlang::sym("Index")
  
  vars <- cor_tbl %>% select(!!var, !!Index) %>% 
    arrange(abs(!!var)) %>% 
    filter(.> abs(0.3),
           . != 1) %>% 
    pull(!!Index)
  
  if (length(vars) > (dim(df)[1] - 1)) {
    vars <- vars[0: (dim(df)[1] - 2)] # otherwise rank deficient matrix
    # check here for what happens with low obs countries
  }
   
  nested_df <- df %>% nest(data = everything())
  nested_df_na <- df_var_na %>% nest(data = everything())

  cat("Went through get_grouped_tibble \n")
  return(list(vars = vars, df = nested_df, df_na = nested_df_na))
}
```


```{r}
# replace identified NA positions
replaceNA_pos <- function(df, var, row_Col_list, preds, gpvar) {
  
  # df = dataframe initial
  # row_col_list = positions of each NA
  # preds = Predictions made by lm or step.model
  # dfname = df name in global enviroment
  
  var = enquo(var)
  row_Col_list = row_Col_list[[sym(gpvar)]]
  rows = row_Col_list$rows
  col  = row_Col_list$cols

  # # group wise 
  # rows_in_gpvar = character(0)
  # for (i in 1:length(rows)) {
  #   if((df %>% pull(Code))[rows[i]] == gpvar) {
  #     rows_in_gpvar = append(rows_in_gpvar, rows[i])
  #   }}
  
  # cat("rows in grped vars are: ", rows_in_gpvar)
  
  for (j in 1:length(rows)) {
    cat("replacing", rows[j], col[1], "\n")
    cat(preds[[j]], "\n")
    df[rows[j], col[1]] <- preds[[j]]
  }
  cat("Went through replace_NA \n")
  return(df)
}

```

```{r}
# repalce remaining NAs with mean
# nothing to do

replace_by_mean <- function(df, var) {
  var = enquo(var)
  
  df %<>% mutate(
    !!var := replace_na(df[[as_label(var)]], 
                        mean(df[[as_label(var)]], na.rm = T))
  )
  cat("running in final replace by mean \n")
  return(df)
}
```


```{r}
# function linear reg by base NSE -- try with quosures
imputeMineTest1 <- function(df, var, ...) {
  # doParallel::registerDoParallel()
  # require(dplyr)
  # require(rlang)
  # require(magrittr)
  
  # print(parent.frame()$i)
  # var = parent.frame()$i %>% sym() # remove for for loops
  var <- enquo(var) 
  dfname <- substitute(df)
  
  posList = list() # pass an empty list to get positions
  
  # initial bind of columns(which have no NA is them (no vert NA)) 
  # and columns we fixing
  df_bind_ini <- bind_cols( df  %>% 
                          select_if(~!any(is.na(.))),
             df %>% 
               select(!!var))
  
  code_list <- df_bind_ini %>% pull(Code) %>% unique()
  
  for (i in 1:length(code_list)) {
    
    gpvar = code_list[i]
    
    df_bind_gpd <- df_bind_ini %>% filter(Code == gpvar)
    
    cat("grouping var is: ", gpvar,"\n")
    
    m = dim(df_bind_gpd)[1]
    
    # group wise na pos
    row_Col_Pos <- getPos(df, !!var, posList, gpvar, m )
    
    if(is_null(row_Col_Pos))next
    
    # get customized grouped tibble
    grouped_tbl <- get_gp_tbl(df = df_bind_gpd, 
                              var = !!var)
    suppressWarnings(
    df_bind <- grouped_tbl$df %>% 
      unnest())

    vars <- grouped_tbl$vars
    
    suppressWarnings(
    df_bind_na <- grouped_tbl$df_na %>% 
      unnest())
    
    
    # check vars
    if(is_empty(vars)){
      warning("No suitable variables to call by. 
              Mean replace initiated")
      
      vars = c('Year')
    }
    
    # make da call
    formula = paste(sym(as_label(var)), 
          paste0(vars, 
                 collapse = " + "), 
          sep = " ~ ") %>% parse_expr()
    
    # linear model
    Model_call <- substitute(
      lm(formula = formula, data = df_bind)
      )
    
    Model_lm <- eval(Model_call)
    preds <- predict.lm(Model_lm, newdata = df_bind_na)
    
    rsq = summary(Model_lm)$r.squared
    
    if (rsq > 0.7) {
      
      # predict here (use above dataframe df_var_na)
      cat("Linear model is used \n")
    }
    
    else {
      warning("R Squared is less than 0.7.
              Implemneting stepAIC model\n")
      
      AICmodel <- function(Model_lm) {
        tryCatch(
          expr = {
            # drop from full_lm model
            Model_AIC <- MASS::stepAIC(Model_lm, 
                                       direction = "both", 
                                       trace = F)
            
            predict.lm(Model_AIC, newdata = df_bind_na)
            
            
            return(c(preds,rsq))
            },
      
          error = function(cond){
            message("AIC model failed. Linear model will be used")
            return(NULL)
            },
          
          warning = function(cond){
            messages("somewarning")
            return(NULL)
            }
        )
      }
      pred_AIC <- AICmodel(Model_lm)
      
      if(is_null(pred_AIC)){
        preds <- predict.lm(Model_lm, newdata = df_bind_na)
      }
      else{
        preds <- pred_AIC
      }
    }
    cat("r squared is:", rsq, "\n")
    
    # replace NA positions # assign to global variable
    df <- replaceNA_pos(df, !!var, 
                  row_Col_Pos, 
                  preds, gpvar)
    
    assign("df", df)
  }
  
  df <- replace_by_mean(df, !!var)
  
  return(df)
  
}

```


```{r}
for (i in c("meat_index", "lower_secnd_edu_index")) {
    imputeMineTest1(test_lm, i)
}
```


```{r}
# test here
res <- imputeMineTest1(test_lm, meat_index)

new_data = data.frame(Year = 2014, 
                      egg_index = 14.57, 
                      entrance_age_index = NA, 
                      life_exp_primary_edu_index = 3.1697, 
                      lower_secnd_edu_index = 109.54 )

predict.lm(eval(res), na.exclude(new_data))
```

```{r}
df_to_lm %>% 
  head(100) %>% 
  filter_at(vars(egg_index), all_vars(!are_na(.)))
```


# Find a possible year range for all indices

```{r}
raw_df %>% 
  group_by(Code) %>% 
  summarise(min = min(Year), 
            max = max(Year))

# find a possible lower bound that's good (possible future approx()) for most of the countries
raw_df %>% select(Code) %>% unique() %>% count()
```



